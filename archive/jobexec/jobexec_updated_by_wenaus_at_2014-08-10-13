{"tags": ["distsw", "pilotjobs"], "refs": [], "refstothis": [], "othertags": ["pilotjobs"], "uses": [{"description": "", "tagref": "htcondor", "created_at": "2014-08-10T13:15:19+00:00", "updated_at": "2014-08-10T13:15:19+00:00", "entity": "jobexec", "subtype": null, "entityref": null, "textref_original": null, "textref": "htcondor", "type": "uses", "id": 2113, "name": "HTCondor"}], "user": "wenaus", "logo": "", "usedby": [{"description": "", "tagref": "autopyfactory", "created_at": "2014-08-10T13:15:19+00:00", "updated_at": "2014-08-10T13:15:19+00:00", "entity": "jobexec", "subtype": null, "entityref": null, "textref_original": null, "textref": "", "type": "usedby", "id": 1690}, {"description": "", "tagref": "glideinwms", "created_at": "2014-08-10T13:15:19+00:00", "updated_at": "2014-08-10T13:15:19+00:00", "entity": "jobexec", "subtype": null, "entityref": null, "textref_original": null, "textref": "", "type": "usedby", "id": 1964, "name": "glideinWMS"}, {"description": "", "tagref": "panda", "created_at": "2014-08-10T13:15:19+00:00", "updated_at": "2014-08-10T13:15:19+00:00", "entity": "jobexec", "subtype": null, "entityref": null, "textref_original": null, "textref": "", "type": "usedby", "id": 1785, "name": "PanDA Production and Distributed Analysis System"}, {"description": "", "tagref": "wms", "created_at": "2014-08-10T13:15:19+00:00", "updated_at": "2014-08-10T13:15:19+00:00", "entity": "jobexec", "subtype": null, "entityref": null, "textref_original": null, "textref": "wms", "type": "usedby", "id": 1873, "name": "Workload Management"}], "loggedin": true, "mytags": ["jobexec"], "ent": {"web": null, "mytag": "jobexec", "description": "<ul>\n<li>LHC computing has been very successful in utilizing the High-Throughput Computing approach in a distributed environment where heterogeneous and increasingly transient resources are provided by a large variety of sites</li>\n<li>In future the LHC requires to marshal more more resources that are more heterogeneous (HPCs, clouds, volunteer computing, \u2026). The need to utilize diverse distributed resources opportunistically extends well beyond the LHC.</li>\n<li>In the Open Science Grid (and the Worldwide LHC Computing Grid) the approach of running a \u201cJob Execution Overlay\u201d based on a Pilot-Job infrastructure has proven very successful\n<ul>\n<li>Pilot jobs get scheduled at sites through site submission interfaces, and \u201cPilot Factories\u201d hide the details of how to submit jobs to site</li>\n<li>Pilot jobs then can pull \u201cpayload\u201d jobs from workload management systems, which orchestrate and schedule the production and analysis workload of the experiments</li>\n<li>This pilot approach is flexible, not tied to any particular VO, and coherently provides features such as monitoring, logging, profiling, etc </li>\n</ul></li>\n<li>Common tools include\n<ul>\n<li>HTCondor, the indispensable backbone, providing scheduling and encapsulating resource access, including site security and access control, traceability etc</li>\n<li>glideinWMS, an extension over HTCondor allowing easy, uniform access to distributed HTCondor resources. Used by CMS, OSG VOs</li>\n<li>The AutoPyFactory system, providing the pilot infrastructure for the PanDA workload management system for Atlas and others</li>\n</ul></li>\n<li>Future: Open Science Grid started to define a \u201cResource Provisioning\u201d architecture to provision CPU resources more dynamically, accountably and configurably, this way enabling coherent access to clouds and allocation-based resources</li>\n</ul>", "created_at": "2014-08-10T13:15:19+00:00", "updated_at": "2014-08-10T13:15:19+00:00", "subtype": "", "location": "", "alltags": " distsw  jobexec  pilotjobs ", "date": "2014-08-10T00:00:00+00:00", "description_markup": "* LHC computing has been very successful in utilizing the High-Throughput Computing approach in a distributed environment where heterogeneous and increasingly transient resources are provided by a large variety of sites\n* In future the LHC requires to marshal more more resources that are more heterogeneous (HPCs, clouds, volunteer computing, \u2026). The need to utilize diverse distributed resources opportunistically extends well beyond the LHC.\n* In the Open Science Grid (and the Worldwide LHC Computing Grid) the approach of running a \u201cJob Execution Overlay\u201d based on a Pilot-Job infrastructure has proven very successful\n    * Pilot jobs get scheduled at sites through site submission interfaces, and \u201cPilot Factories\u201d hide the details of how to submit jobs to site\n    * Pilot jobs then can pull \u201cpayload\u201d jobs from workload management systems, which orchestrate and schedule the production and analysis workload of the experiments\n    * This pilot approach is flexible, not tied to any particular VO, and coherently provides features such as monitoring, logging, profiling, etc \n* Common tools include\n    * HTCondor, the indispensable backbone, providing scheduling and encapsulating resource access, including site security and access control, traceability etc\n    * glideinWMS, an extension over HTCondor allowing easy, uniform access to distributed HTCondor resources. Used by CMS, OSG VOs\n    * The AutoPyFactory system, providing the pilot infrastructure for the PanDA workload management system for Atlas and others\n* Future: Open Science Grid started to define a \u201cResource Provisioning\u201d architecture to provision CPU resources more dynamically, accountably and configurably, this way enabling coherent access to clouds and allocation-based resources", "type": "task", "id": 1279, "allmytags": " jobexec ", "name": "Job Execution and Resource Provisioning"}, "tagname": "jobexec", "image": {}}